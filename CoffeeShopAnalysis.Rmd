---
title: "Coffee Shop Exploratory Analysis"
author: "John Ghio Lopez"
date: "2024-04-12"
output:
  prettydoc::html_pretty:
    toc: true
    theme: architect
---

# **Data Background**

The dataset comprises transactional records from Maven Roasters, a fictional NYC-based coffee shop operating across three distinct locations. It encompasses comprehensive details such as transaction dates, timestamps, geographical specifics, and product-level information.

Based on the dataset information, these are the columns and their description:

+------------------+------------+----------------------------------------------------------------+
| **Field**        | **Type**   | **Description**                                                |
+==================+============+================================================================+
| transaction_id   | Numeric    | Unique identifier for each transaction.                        |
+------------------+------------+----------------------------------------------------------------+
| transaction_date | Date       | Date when the transaction occurred.                            |
+------------------+------------+----------------------------------------------------------------+
| transaction_time | Time       | Time of the transaction.                                       |
+------------------+------------+----------------------------------------------------------------+
| transaction_qty  | Numeric    | Quantity of products\                                          |
|                  |            | purchased in a transaction.                                    |
+------------------+------------+----------------------------------------------------------------+
| store_id         | Numeric    | Unique identifier for each store location.                     |
+------------------+------------+----------------------------------------------------------------+
| store_location   | Text       | Name or description of the store's\                            |
|                  |            | physical location.                                             |
+------------------+------------+----------------------------------------------------------------+
| product_id       | Numeric    | Unique identifier for each product sold.                       |
+------------------+------------+----------------------------------------------------------------+
| unit_price       | Numeric    | Price of a single unit of the product\                         |
|                  |            | in the transaction.                                            |
+------------------+------------+----------------------------------------------------------------+
| product_category | Text       | General category to which the product belongs\                 |
|                  |            | (e.g., Coffee, Tea, Drinking Chocolate).                       |
+------------------+------------+----------------------------------------------------------------+
| product_type     | Text       | Specific type or variant of the product\                       |
|                  |            | (e.g., Gourmet brewed coffee, Brewed Chai tea, Hot chocolate). |
+------------------+------------+----------------------------------------------------------------+
| product_detail   | Text       | Additional details about the product\                          |
|                  |            | (e.g., specific flavor, size, or blend)                        |
+------------------+------------+----------------------------------------------------------------+

# **Objectives**

Our primary goal in this analysis is to understand the data and generate valuable insights for future decision-making. We will explore the data as much as possible. We can achieve our primary goal by performing the following:

1.) **Identify the data structure**: Through exploratory analysis, we can recognize the various data types that are present, how they are distributed, and the general structure of the data.

2.) **Ensure data quality**: We will evaluate the reliability and quality of the data by detecting anomalies and outliers in the dataset, addressing missing values, and correcting data type errors.

2.) **Identify patterns and relationships:** Analyze the dataset's pattern and the relationship between its columns by examining it and applying different techniques to find hidden patterns.

# **Environment Setup**

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse) # General
library(lubridate) # Date Converter
library(tidycomm)  # Statistical Summary
library(scales)    # Numerical Labelling
library(e1071)     # Skew Scalling / Class Analysis
library(reshape2)  # Restructure and Aggregate Data
 
library(ggplot2)   # Data Visualization
library(ggthemes)  # Data Visual Theme
library(patchwork) # Combining Visuals

library(RPostgres) # PostgreSQL Database

 # General Color
 color = '#2879D8'
  
 # General Theme
 theme_set(theme_fivethirtyeight())
```

## Connecting to Database

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Credentials 
warehouse <- config::get('datawarehouse')

# Create connection to database
con <- dbConnect(RPostgres::Postgres(),
                 dbname = warehouse$database,
                 host = warehouse$hostname,
                 port = warehouse$portid,
                 user = warehouse$username,
                 password = warehouse$password)
```

## Extracting Data

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Extracting Data
data <- dbGetQuery(con, "SELECT * FROM coffee_shop")

# Disconnecting to Database
dbDisconnect(con)
```

Let's take a quick look of the data

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Quick look
print(head(data, 5))
```

## Data Cleaning

**Data Types**

```{r echo=FALSE, message=FALSE, warning=FALSE}
str(data)
```

We will have several changes to our data types and columns to make our analysis easier:

-   **transaction_id**: from **integer** to **character** since it's a unique identifier for each transaction.

-   **transaction_date**: from **character** to **date** it will make an unclear output if set to character.

-   **transaction_time:** from **character** to **timestamps** it will make an unclear output if set to character.

-   **store_id**: from **integer** to **character** since it's a unique identifier for each store location.

-   **product_id**: from **integer** to **character** since it's a unique identifier for each product.

**Converting Data Types**

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Transaction ID to character
data$transaction_id <- as.character(data$transaction_id)

# Transaction Date to Date
data$transaction_date <- ymd(data$transaction_date)

# Transaction Time to Datestamps
data$transaction_time <- hms(data$transaction_time)

# Store ID to character
data$store_id <- as.character(data$store_id)

# Product ID to character
data$product_id <- as.character(data$product_id)
```

Now that we have done converting columns, let's proceed to our next step.

## Missing Values

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Total number of rows
total_rows <- nrow(data)

# Check the missing vales in each column
missing_value <- colSums(is.na(data))

# Calculating the proportion of missing values
missing_proportion <- (missing_value / total_rows) * 100

# Combine into dataframe
missing_data <- data.frame(missing_count = missing_value, proportion = missing_proportion)

# Result
missing_data
```

As shown table above, we can see we have complete record, no missing values at all in our data which will lead us straight to our next step.

## Feature Creation

**Revenue**

We can create a new column from our existing columns by multiplying the **quantity** and **price.**

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Adding Feature: Revenue
data$revenue <- (data$transaction_qty * data$unit_price)
```

**Size**

We can extract the size detail of every transactions from product details provided in the data and create column

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Addding Feature: Size
data <- data %>% 
  mutate(size = ifelse(str_detect(product_detail, 'Rg') == TRUE, 'Regular', 
                       ifelse(str_detect(product_detail, 'Lg') == TRUE, 'Large', 
                              ifelse(str_detect(product_detail, 'Sm') == TRUE, 'Small', 'Undefined'))))
```

**Hour, Day of Week, and Month**

Extracting the day of the week, month, and year from the **Transaction Date** column that will help us to understand the transaction trend later on.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Adding feature: Hour
data$hour <- as.character(hour(data$transaction_time))

# Adding feature: Day of week
data$dayofweek <- as.character(wday(data$transaction_date))

# Adding feature: Month
data$month <- as.character(month(data$transaction_date))
```

**Removal of Columns**

Since some of the columns in our dataset are already represented in other formats, we will be removing those extra columns.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Removal of columns
data <- subset(data, select = -c(transaction_time, store_id, product_id, product_detail))
```

Let's take a look at our dataset before continuing.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Glimpse data
glimpse(data)
```

# **Exploratory Analysis**

## **Univariate Analysis**

### Summary Statistics

**Numerical Variables Summary Statistics**

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Numerical Variables Summary Statistics
summary(data[c('transaction_date', 'transaction_qty', 'unit_price', 'revenue')])
```

**Insights:**

-   **Date Range**: The dataset spans from January 1, 2023 to June 30, 2023.

-   **Potential Outliers:** Revenue shows potential outliers with huge values.

-   **Right-Skewed Distribution:** Quantity, and Revenue shows their mean are higher than median indicating possible right-skewed distribution.

**Categorical Variables Summary Statistics**

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Categorical Variables Summary Statistics
describe_cat(data)
```

**Insights:**

-   **Top Store Location:** Out of three locations, Hell's Kitchens' place is the most popular, accounting for 50,735 transactions.

-   **Top Category:** Coffee was the most selling category accounting for 58,416 transactions.

-   **Top Product:** Brewed Chai Tea was the most selling product with 17,183 sold product.

-   **Top Size:** Regular size was the most frequent ordered size with 45,789 sold.

-   **Busiest Month:** June has the most transactions, recording 35,352 transactions.

-   **Busiest Day:** Friday was the popular day with 21,701 transactions.

-   **Busiest Hour:** Around 10 a.m. was the busiest hour for the business, with 18,545 transactions took place during this period.

### Distribution

**Numerical Variables Distribution**

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Quantity Boxplot
quantity_boxplot <- data %>%
  ggplot(aes(y = transaction_qty)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') + 
  labs(title = 'Quantity Boxplot',
       y = 'QUANTITY') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Price Boxplot
price_boxplot <-data %>%
  ggplot(aes(y = unit_price)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') +
  labs(title = 'Price Boxplot',
       y = 'PRICE (IN USD)') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Revenue Boxplot  
revenue_boxplot <- data %>%
  ggplot(aes(y = revenue)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') +
  labs(title = 'Revenue Boxplot',
       y = 'REVENUE (IN USD)') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Combining Boxplots
quantity_boxplot | price_boxplot | revenue_boxplot 
```

Due to outliers, it's difficult to visualize the **interquartile range** of these columns: **Price** and **Revenue**. To better visualize it, we can temporarily zoom in on our y-axis.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Quantity Boxplot
quantity_boxplot <- data %>%
  ggplot(aes(y = transaction_qty)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') +
  labs(title = 'Quantity Boxplot',
       y = 'QUANTITY') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Price Boxplot
price_boxplot <-data %>%
  ggplot(aes(y = unit_price)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') +
  coord_cartesian(y = c(0, 10)) +
  labs(title = 'Price Boxplot',
       y = 'PRICE (IN USD)') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Revenue Boxplot  
revenue_boxplot <- data %>%
  ggplot(aes(y = revenue)) +
  geom_boxplot(color = color,
               fill = color,
               alpha = 0.2) +
  stat_boxplot(color = color,
               geom = 'errorbar') +
  coord_cartesian(y = c(0, 20)) +
  labs(title = 'Revenue Boxplot',
       y = 'REVENUE (IN USD)') +
  theme(axis.title = element_text(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5,
                                  face = 'bold',
                                  size = 15))

# Combining Boxplots
quantity_boxplot | price_boxplot | revenue_boxplot 
```

**Insights:**

-   **Quantity:** The quantity for transactions range from 1 to 2. There are outliers exceeding more than 4 quantity.
-   **Price:** The price falls between 2.5 USD to 3.75 USD. Outliers exceeding above 5, and we have on exceptional reaching over 40.
-   **Revenue:** The generated revenue from transaction falls between 3 USD to 6 USD. There are outliers above 10 USD, one reaching over 300 USD.

**Dealing with Outliers**

As noted earlier in summary statistics of numerical variables, all variables show potential outliers. Based on our boxplot, **Revenue** column reveals a massive value generated. This outliers in **Revenue** column are exceeding more than 300 USD, before we deal with this outliers, let's investigate it first.

```{r echo=FALSE, message=FALSE, warning=FALSE}
print(filter(data, revenue > 300))
```

As we can see, the transactions are constant in terms of the quantity of units purchased, the store's location, and the type or category of products purchased. Although we can presume that all of these transactions are either from the same customer or from different customers, but, due to insufficient information and proof, we can't prove these assumptions.

Furthermore, we will have to remove these transactions from our data set to keep the consistency and accuracy for further analysis.

**Removing Outliers**

```{r echo=TRUE, message=FALSE, warning=FALSE}
data <- filter(data, revenue < 300)
```

Now that we removed the outliers, we will continue our analysis using **Histograms**

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Quantity Histogram
quantity_histogram <- data %>% 
  ggplot(aes(x = transaction_qty)) +
  geom_histogram(bins = 200,
                 fill = color) +
  labs(title = 'Quantity Histogram',
       x = 'QUANTITY',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Price Histogram
price_histogram <- data %>% 
  ggplot(aes(x = unit_price)) +
  geom_histogram(bins = 200,
                 fill = color) +
  labs(title = 'Price Histogram',
       x = 'PRICE (IN USD)',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Revenue Histogram
revenue_histogram <- data %>% 
  ggplot(aes(x = revenue)) +
  geom_histogram(bins = 200,
                 fill = color) +
  labs(title = 'Revenue Histogram',
       x = 'REVENUE (IN USD)',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Combining Histograms
quantity_histogram / price_histogram / revenue_histogram
```

As we mentioned earlier in summary statistics, all numerical variables are possible right-skewed distributed. We can confirm this by measuring their skewness.

```{r echo=FALSE, message=FALSE, warning=FALSE}
price_skew <- skewness(data$unit_price)
quantity_skew <- skewness(data$transaction_qty)
revenue_skew <- skewness(data$revenue)

print(paste("Price Skewness:", as.character(price_skew)))
print(paste("Quantity Skewness:", as.character(quantity_skew)))
print(paste("Revenue Skewness:", as.character(revenue_skew)))
```

As shown above, we can see that all numerical variables are indeed right-skewed distributed, with **Price** column being the most noticeable.

**Categorical Variable Distribution**

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Product Category Data
product_category <- data %>% 
  select(product_category) %>% 
  group_by(product_category) %>% 
  count() %>% 
  arrange(-n) %>% 
  head(10)

# Product Type Data
product_type <- data %>% 
  select(product_type) %>% 
  group_by(product_type) %>% 
  count() %>% 
  arrange(-n) %>% 
  head(10)

# Product Category Bar Chart
category_barchart <- product_category %>% 
  ggplot(aes(y = fct_reorder(product_category, n),
             x = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Product Category Distribution', 
       y = 'Product Category',
       x = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  hjust = 1.2,
                                  size = 16)) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Product Type Bar Chart
type_barchart <- product_type %>% 
  ggplot(aes(y = fct_reorder(product_type, n),
             x = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Product Type Distribution', 
       y = 'Product Type',
       x = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  hjust = 1.2,
                                  size = 16)) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))


# Combining Bar Charts
category_barchart | type_barchart
```

**Insights:**

-   **Product Category:** Coffee was the best selling product category with 58,416 transactions.

-   **Product Type:** Brewed Chai Tea, with 17,183 transactions, was the most popular product type under the tea category.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Store Location Data
store_location <- data %>% 
  select(store_location) %>% 
  group_by(store_location) %>% 
  count()

# Size Distribution Data
size <- data %>% 
  select(size) %>% 
  group_by(size) %>% 
  count()

# Store Location Bar Chart 
store_barchart <- store_location %>% 
  ggplot(aes(y = fct_reorder(store_location, n),
             x = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Store Location Distribution', 
       y = 'Store Location',
       x = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  hjust = 0.6)) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Size Bar Chart
size_barchart <- size %>% 
  ggplot(aes(y = fct_reorder(size, n),
             x = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Cup Size Distribution',
       y = 'Size',
       x = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  hjust = 0.6)) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))

store_barchart | size_barchart
```

**Insights:**

-   **Store Location:** Hell's kitchen was the popular with more than 50,000 transactions. Astoria being the second, only few hundreds off with Hell's kitchen.
-   **Cup Size:** Regular was the most ordered cup size, large being the second. We can see that we have massive amount of undefined cup size with only a minimum Amount of difference to Large

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}

# Hour Data
hour <- data %>% 
  select(hour) %>% 
  group_by(hour) %>% 
  count()

# Day of Week Data
dayofweek <- data %>% 
  select(dayofweek) %>%
  group_by(dayofweek) %>% 
  count()

# Month Data
month <- data %>% 
  select(month) %>% 
  group_by(month) %>% 
  count()

# Hour Bar Chart
hour_barchart <- hour %>% 
  ggplot(aes(x = fct_reorder(hour, as.numeric(hour)),
             y = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Hourly Distribution', 
       x = 'Hour',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  size = 16,
                                  hjust = .6)) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Day of Week Bar Chart
dayofweek_barchart <- dayofweek %>% 
  ggplot(aes(x = dayofweek,
             y = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'DayOfWeek Distribution', 
       x = 'Day of Week',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  size = 16,
                                  hjust = 0.2)) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Month Bar Chart
month_barchart <- month %>% 
  ggplot(aes(x = month,
             y = n)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Month Distribution', 
       x = 'Month',
       y = 'Frequency') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold",
                                  size = 16,
                                  hjust = .6)) +
  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale()))

# Combining Barcharts
hour_barchart | dayofweek_barchart | month_barchart 
```

**Insights:**

-   **Hourly:** The shop's busiest hours were commonly in the morning based on the hourly distribution, which showed a pattern in customer behavior. 10 AM is the busiest time of day at the store, with over 18,000 transactions.

-   **DayOfWeek:** A stable trend all throughout the week with an average of 20,000 transactions.

-   **Month:** An increasing trend shown in Month distribution, as June was the highest with more than 30,000 transactions.

## **Bivariate & Multivariate Analysis**

### Numerical Variables Relationship

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Filtering data only numericals
numerical <- data %>% select(Price = unit_price, Quantity = transaction_qty, Revenue = revenue)

# Correlating the data and rounding
numerical_cor <- round(cor(numerical), 2)

# Melting the data using Reshape package
numerical_cor <- melt(numerical_cor)

# Numerical Corelation Heatmap Visual
numerical_cor %>% 
  ggplot(aes(x = Var1,
             y = Var2,
             fill = value)) +
  geom_tile(color = "white",
            lwd = 1.5,
            linetype = 1) +
  geom_text(aes(label = value), 
            color = "white", 
            size = 4) +
  coord_fixed() +
  labs(x = NULL,
       y = NULL) +
  theme(legend.position = "none")
```

As shown above, we have high correlations between **unit price** and **revenue**, and low correlation between **revenue** and **quantity.**

Let's check the numerical relationship using pair plot.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Renaming columns for better presentation
numeric_data <- data %>% select(Price = unit_price, Quantity = transaction_qty, Revenue = revenue)

# Pair plot function
pairs(numeric_data[, c('Price', 'Quantity', 'Revenue')],
      col = color,
      pch = 19,
      cex = 0.8 )
```

The strong positive correlation between **Revenue** and **Unit** **Price** is clear. The behavior of customers, who typically purchase higher-quality goods, makes this possible. We can presume that expensive coffee is a better product. Customers in this situation are more likely to spend money on high-quality goods, which boosts overall sales.

On the other hand, we can observe the low correlation between **Quantity** and **Revenue.** This is made possible by the fact that the coffee industry, where our dataset is derived from, typically values quality over quantity in consumer behavior. Only a tiny proportion of customers in the transaction purchased more than two coffees, as can be seen in our transaction quantity distribution.

### Sales Performance

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Revenue Data and Bar Chart
data %>% 
  select(transaction_date, revenue) %>% 
  group_by(transaction_date) %>% 
  summarise(revenue = sum(revenue)) %>% 
  ggplot(aes(y = revenue,
             x = transaction_date)) +
  geom_line(linewidth = 0.8,
            color = color) +
  labs(title = 'Sales Performance',
       subtitle = 'January 2023 to June 2023',
       x = 'Month',
       y = 'Revenue (In USD)') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_date(date_labels = "%b",
               date_breaks = "1 month")
```

The sales revenue show a strong increasing incline pattern from January to end of June as shown above, with June reaching the highest point in sales performance; with sales exceeding 6,000 USD.

If we thoroughly examine the trend line, we can see that there is a declining trend at the beginning of each month and a significant fall at the end of each month. April until the end of June is when it's most noticeable. We can look into this unusual pattern in more detail.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Daily Average Product Price Data & Trend
daily_mean_price <- data %>% 
  mutate(day = as.numeric(day(transaction_date))) %>% 
  select(day, unit_price) %>% 
  group_by(day) %>% 
  summarise(price = mean(unit_price)) %>% 
  ggplot(aes(x = day,
             y = price)) +
  geom_line(color = color,
            size = 1) +
  labs(title = 'Daily Average Product Price',
       y = 'Price (in USD)',
       x = 'Day') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_continuous(breaks = seq(1, 31, 1))

# Daily Average Product Quantity Data & Trend
daily_mean_quantity <- data %>% 
  mutate(day = as.numeric(day(transaction_date))) %>% 
  select(day, transaction_qty) %>% 
  group_by(day) %>% 
  summarise(quantity = mean(transaction_qty)) %>% 
  ggplot(aes(x = day,
             y = quantity)) +
  geom_line(color = color,
            size = 1) +
  labs(title = 'Daily Average Product Quantity',
       y = 'Quantity',
       x = 'Day') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_continuous(breaks = seq(1, 31, 1))

# Combining Both Trend Line
daily_mean_price / daily_mean_quantity
```

If we examine closely, the price trend line fluctuates. But quantity is the opposite. It displays the price flipped. The average quantity decreased as the average product price increased. We could assume that marketing techniques like sales, discounts, and the introduction of new or distinctive products drive consumers to purchase costly products.

Let's now delve to daily average sales by week.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Daily Average Sales Data
daily_mean <- data %>% 
  select(dayofweek, transaction_date, revenue) %>% 
  group_by(dayofweek, transaction_date) %>% 
  summarise(revenue = sum(revenue)) %>%  
  group_by(dayofweek) %>% 
  summarise(revenue = mean(revenue))

# Chaninging week column from numerical value to character value
daily_mean$dayofweek <- recode_factor(daily_mean$dayofweek,
                                      '1' = 'Sun',
                                      '2' = 'Mon',
                                      '3' = 'Tue',
                                      '4' = 'Wed',
                                      '5' = 'Thu',
                                      '6' = 'Fri',
                                      '7' = 'Sat')

# Daily Average Sales Trend Line
daily_mean %>% 
  ggplot(aes(x = dayofweek,
             y = revenue,
             group = 1)) + 
  geom_line(color = color,
            linewidth = 1) +
  labs(title = 'Daily Average Sales By Week ',
       y = 'Revenue (in USD)',
       x = 'Day') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold"))
```

The average daily sales were lowest on Sunday, with a sharp increase on Monday and a sharp decline on Tuesday, indicating an unusual pattern in the purchasing behavior of the customers. We can see that the trend line has a constant increase until Friday despite the initial dip. On Saturday, the daily average fell once more.

The weekday started with a sharp spike, which was followed by a steep decrease and a slowly increasing ascent until the end of the workday. This tendency may be related to the high volume of clients who are working during the workday. Customers that enjoy food and services and are searching for quick and convenient solutions. The sales are typically higher on weekdays.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Hourly Average Sales Data
hour_mean_revenue <- data %>% 
  select(hour, transaction_date, revenue) %>% 
  group_by(hour, transaction_date) %>% 
  summarise(revenue = sum(revenue)) %>% 
  group_by(hour) %>% 
  summarise(revenue = mean(revenue))

# Hourly Average Sales Trend Line
hour_mean_revenue %>% 
  ggplot(aes(y = revenue,
             x = fct_reorder(hour, as.numeric(hour)),
             group = 1)) +
  geom_line(color = color,
            linewidth = 1) +
  labs(title = 'Hourly Average Sales',
       y = 'Revenue (in USD)',
       x = 'Hour (24 Hours)') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold"))
```

The data shows that business hours begin at 6 in the morning. An early-morning steep curve suggests that most business sales occur more frequently during this time. From 8 a.m. up until 10 a.m. are the most active. As time goes by, business revenues begin to sharply fall, starting around 11 a.m. after which there was a short and constant decrease until the end of business hours.

### Sales Performance By Location

```{r echo=FALSE, fig.height=7, fig.width=10}
# Revenue Distribution By Location
data %>%
  select(revenue, store_location) %>%
  group_by(store_location) %>%
  summarise(revenue = sum(revenue)) %>%
  ggplot(aes(x = revenue,
             y = fct_reorder(store_location, revenue))) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Store Sales Distribution',
       y = 'Store',
       x = 'Revenue (in USD)') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))
```

As can be seen above, Hell's Kitchen Store was ranked highest out of the three stores. There's only minimal difference in revenue between these three establishments.

We can further analyze the data for each store if there's an underlying pattern for consumer behavior. We can investigate this by analyzing the median quantity and price for every store.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Median Quantity Purchased 
median_quantity <- data %>%
  select(store_location, transaction_qty) %>%
  group_by(store_location) %>%
  summarise(quantity = median(transaction_qty)) %>% 
  ggplot(aes(y = store_location,
             x = quantity)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Median Quantity Purchased',
       y = 'Store',
       x = 'Quantity') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold"))

# Median Price Purchased
median_price <- data %>% 
  select(store_location, unit_price) %>% 
  group_by(store_location) %>% 
  summarise(unit_price = median(unit_price)) %>% 
  ggplot(aes(y = store_location,
             x = unit_price)) + 
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Median Price Purchased',
       y = 'Store',
       x = 'Price (in USD)') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) 

# Combining both graph

median_quantity | median_price
```

The median quantity and price purchases give the same outcome in every store. This indicates that regardless of the different store locations, the quantity and price purchased is constant. Given the consistency of the median quantity throughout the stores, this provides no significant context for our analysis.

NOTE: The median was used instead of the mean. The data has outliers that could potentially influence the result of the mean and give unrealiable insights.

### Sales Performance by Category, Product, and Size

First, let's determine the number of category this coffee shop offers.

```{r echo=FALSE, message=FALSE, warning=FALSE}
unique <- n_distinct(data$product_category)

print(paste("Total Category:", as.character(unique)))
```

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
data %>% 
  select(product_category, revenue) %>% 
  group_by(product_category) %>% 
  summarise(revenue = sum(revenue)) %>% 
  ggplot(aes(x = revenue,
             y = fct_reorder(product_category, revenue))) +
  geom_bar(fill = color,
           stat = 'identity') +
  labs(title = 'Top Category with Highest Sales',
       y = 'Category',
       x = 'Total Sales (in USD)') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))
```

With sales of roughly 250,000 USD, coffee was the leading category. Tea came in second with approximately 195,000 USD in sales. There is a noticeable difference in margin between tea and the bakery category.

We can analyze the trend of these categories average daily sales for a 6-month period. Providing an insight into how these categories evolve over time. 

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
data %>% 
  mutate(day = day(transaction_date)) %>% 
  select(product_category, day, revenue) %>% 
  group_by(product_category, day) %>% 
  summarise(revenue = mean(revenue)) %>% 
  ggplot(aes(y = revenue,
             x = day,
             color = product_category)) +
  geom_line(linewidth = 1) +
  labs(title = 'Category Daily Average Sales',
       y = 'Revenue (in USD)',
       x = 'Day',
       color = 'Product Category') +
  theme(axis.title = element_text(),
        plot.title = element_text(face = "bold")) +
  scale_x_continuous(breaks = seq(1, 31, 1))
```

When it comes to average daily sales, the category of coffee beans constantly leads the trend. It's noticeable that this category fluctuates, particularly on day seventeen, assuming this category is caused by sales or promotional activity.

The majority of the categories' daily average sales—bread, coffee, drinking chocolate, loose tea, tea, and flavors—show consistency. If we notice, several products' sales consistently start on the 2nd week of each month. It's possible that the business conducts restocking every first week of the month.

This insight is connected to consumer purchasing behavior, in which there was a fluctuating trend in the daily average product and quantity purchased. These categories—branded and coffee beans—make significant contributions to shifts or fluctuations in patterns. 

Let's look at products. But first, let's determine the number of products this coffee shop offers.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Number of Unique Products
unique <- n_distinct(data$product_type)

print(paste("Total Products:", as.character(unique)))
```

The coffee shop offers 29 unique products, let's continue

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
# Top Product with Highest Sales
data %>% 
  select(product_type, revenue) %>% 
  group_by(product_type) %>% 
  summarise(revenue = sum(revenue)) %>% 
  arrange(-revenue) %>% 
  head(10) %>% 
  ggplot(aes(y = fct_reorder(product_type, revenue),
             x = revenue)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Top Product with Highest Sales',
       y = 'Product',
       x = 'Total Sales (in USD)') +
  theme(plot.title = element_text(face = "bold")) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))
```

These are the best-selling products out of the coffee shop's 29 distinctive products. With sales of more than 80,000 USD, Barista Espresso, which falls within the coffee category. Then came Gourmet Brewed Coffee, Hot Chocolate, and Brewed Chai Tea, all of which had sales exceeding \$65,000 USD.

```{r echo=FALSE, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}
data %>% 
  select(size, revenue) %>% 
  group_by(size) %>% 
  summarise(revenue = sum(revenue)) %>% 
  ggplot(aes(y = fct_reorder(size, revenue),
             x = revenue)) +
  geom_bar(stat = 'identity',
           fill = color) +
  labs(title = 'Top Cup Size with Highest Sales',
       y = 'Size',
       x = 'Total Sales (in USD)') +
  theme(plot.title = element_text(face = "bold")) +
  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale()))
```

Standing at the top of the list with sales of over 250,000 USD was Large, followed by undefined at exceed 210,000 USD and regular at approximately 200,000 USD. Assuming that small sizes are unpopular, we can see that small sizes only had small sales.\
\
The undefined size belongs to another category, such as food, branded, or custom-sized cups made from other products.

# **Conclusion**

In summary, the company has grown impressively, with overall revenue of 698,812 USD increasing steadily over the previous half-year. Another important factor contributing to fluctuations in sales, especially in the middle of the month is the introduction of premium and branded products. Additionally, consumers show a preference for high-quality products, which increases sales for the business. Interesting trends can be seen in the analysis of sales patterns, with Monday standing out as the busiest day in the early morning hours between 8 a.m. up until 10 a.m. having the largest number of customers. Revenue differs minimally between branches, despite these fluctuations. The category of coffee has the lead, accounting for 38.6% of total sales. Barista Espresso generates the most revenue, but brewed chai tea is the most popular in terms of sales quantity. Lastly, it appears that customers prefer large and regular cup sizes.
